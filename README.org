*  PARIETAL
PARIETAL: Yet another deeP leARnIng brain ExTrAtion tooL

** Why another skull-stripping method?
During the last years, we have happily use each of the already available tools that have been proposed. However, these methods are not always accurate enough for our needs or when accurate, they are slow for fast inference. Hopefully, several brain MRI datasets have been released, such as the [[https://sites.google.com/view/calgary-campinas-dataset/home][Campinas]] dataset, permitting researchers to train deep learning models that hopefully will reduce both the accuracy and time drawbacks.

In this aspect, several deep learning method have been already proposed for accurate brain extraction. PARIETAL is another one, trying to perform a fast and protocol independent skull extraction. Our qualitative and quantitative experiments show a high performance on different datasets, even without retraining on unseen protocols.


** Installation
PARIETAL uses the amazing [[www.pytorch.org][Pytorch]] deep learning toolkit. All necessary packages can be installed from =pip= as follows:

#+begin_src python
pip install -r requirements
#+end_src

** How to use it:
In order to run the PARIETAL model, just run =python run_skull.py --help= to see all the available options:

#+begin_SEC bash
python run_skull.py --help
#+end_src

*** Mandatory parameters:
- input_image (=--input_image=): T1 nifti image to process
- out_name (=--out_name=): Output name for the skull-stripped image

*** Optional parameters:
- binary threshold (=--threshold=): output threshold used to binarize the skull-stripped image (default=0.5)
- gpu use (=--gpu=): use GPU for faster inference (default=No)
- gpu number (=--gpu_number=): Which GPU number to use (default=0)
- trained model (=--model=): Trained model to use to perform the inference (default: Campinas model)
- verbose (=--verbose=): show useful information

*** GPU vs CPU use:
The model can run with both GPU or a decent CPU. In most of the experiments performed, PARIETAL can perform the brain extraction of a T1-w image in less than 10 seconds when using GPU and about 2 minutes when running on the CPU (see performance experiments for a more complete analysis).

** Performance:
We have compared the performance of PARIETAL with several state-of-the-art tools already available and also with respect to some other deep learning methods. In other to do so, we have run PARIETAL on different public available datasets such as [[http://www.oasis-brains.org/][OASIS]], [[https://resource.loni.usc.edu/resources/atlases-downloads/][LBPA40]] and the [[https://sites.google.com/view/calgary-campinas-dataset/home][Campinas]] dataset.

*** Campinas dataset:

Performance evaluation against the 12 manual masks from the Campinas dasaset.  Values for the rest of the methods are extracted from the [[https://doi.org/10.1016/j.artmed.2019.06.008][Lucena et al. 2019]] paper:

| method             |  Dice | Sensitivity | Specificity |
|--------------------+-------+-------------+-------------|
| [[https://github.com/ANTsX/ANTs][ANTs]]               | 95.93 |       94.51 |       99.70 |
| [[https://www.sciencedirect.com/science/article/pii/S1053811916306176?via%253Dihub][BEAST]]              | 95.77 |       93.84 |       99.76 |
| [[https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/BET/UserGuide][BET]]                | 95.22 |       98.26 |       99.13 |
| [[http://brainsuite.org/processing/surfaceextraction/bse/][BSE]]                | 90.48 |       91.44 |       98.64 |
| [[https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2408865/][HWA]]                | 91.66 |       99.93 |       97.83 |
| [[https://www.frontiersin.org/articles/10.3389/fninf.2013.00032/full][MBWSS]]              | 95.57 |       92.78 |       99.48 |
| [[https://www.sciencedirect.com/science/article/pii/S1053811916306176?via%253Dihub][OPTIBET]]            | 95.43 |       96.13 |       99.37 |
| [[https://sites.google.com/site/jeiglesias/ROBEX][ROBEX]]              | 95.61 |       98.42 |       99.13 |
| [[https://www.ncbi.nlm.nih.gov/pubmed/15250643][STAPLE (previous)]]  | 96.80 |       98.98 |       99.38 |
|--------------------+-------+-------------+-------------|
| [[http://dx.doi.org/10.1016/j.neuroimage.2017.08.021][Silver-masks]]       | 97.13 |       96.82 |       99.70 |
|--------------------+-------+-------------+-------------|
| [[https://doi.org/10.1016/j.artmed.2019.06.008][CONSNet]]            | 97.18 |       98.91 |       99.46 |
| *PARIETAL*         | 97.20 |       96.80 |       97.80 |
|--------------------+-------+-------------+-------------|


*** LBPA40 dataset:

Performance evaluation against the 40 manual masks from the LBPA40 dasaset.  Values for the rest of the methods are extracted from the [[https://doi.org/10.1016/j.artmed.2019.06.008][Lucena et al. 2019]] paper:

| method                               |  Dice | Sensitivity | Specificity |
|--------------------------------------+-------+-------------+-------------|
| [[https://github.com/ANTsX/ANTs][ANTs]]                                 | 97.25 |       98.98 |       99.17 |
| [[https://www.sciencedirect.com/science/article/pii/S1053811916306176?via%253Dihub][BEAST]]                                | 96.30 |       94.06 |       99.76 |
| [[https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/BET/UserGuide][BET]]                                  | 96.62 |       97.23 |       99.27 |
| [[https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2408865/][HWA]]                                  | 92.51 |       99.89 |       97.02 |
| [[https://www.frontiersin.org/articles/10.3389/fninf.2013.00032/full][MBWSS]]                                | 96.24 |       94.40 |       99.68 |
| [[https://www.sciencedirect.com/science/article/pii/S1053811916306176?via%253Dihub][OPTIBET]]                              | 95.87 |       93.35 |       99.74 |
| [[https://sites.google.com/site/jeiglesias/ROBEX][ROBEX]]                                | 96.77 |       96.50 |       99.50 |
| [[https://www.ncbi.nlm.nih.gov/pubmed/15250643][STAPLE (previous)]]                    | 97.59 |       98.14 |       99.46 |
|--------------------------------------+-------+-------------+-------------|
| [[https://doi.org/10.1016/j.artmed.2019.06.008][CONSNet]] (Campinas model)             | 97.35 |       98.14 |       99.45 |
| *PARIETAL* (Campinas model)          | 97.25 |       96.10 |       98.40 |
|--------------------------------------+-------+-------------+-------------|
| [[https://doi.org/10.1016/j.artmed.2019.06.008][CONSNet]] (trained on LBPA40)          | 98.47 |       98.55 |       99.75 |
| [[https://ieeexplore.ieee.org/abstract/document/7961201][auto UNET Salehi]] (trained on LBPA40) | 97.73 |       98.31 |       99.48 |
| [[https://ieeexplore.ieee.org/abstract/document/7961201][Unet Salehi (trained on LBPA40)]]      | 96.79 |       97.22 |       99.34 |
| [[https://www.sciencedirect.com/science/article/pii/S1053811916000306?via%253Dihub][3DCNN Kleesiek]]  (trained on LBPA40)  | 96.96 |       97.46 |       99.41 |
|--------------------------------------+-------+-------------+-------------|

*** OASIS datset

Finally, results for the OASIS dataset are also shown. Values for the rest of the methods are extracted from the [[https://doi.org/10.1016/j.artmed.2019.06.008][Lucena et al. 2019]] paper:


** Versions:
 - v0.1: first usable version

** References

1. Souza, R., Lucena, O., Garrafa, J., Gobbi, D., Saluzzi, M., Appenzeller, S., … Lotufo, R. (2017). An open, multi-vendor, multi-field-strength brain MR dataset and analysis of publicly available skull stripping methods agreement. NeuroImage, 170, 482–494. [[https://doi.org/10.1016/j.neuroimage.2017.08.021%20][(link)]]

2. Lucena, O., Souza, R., Rittner, L., Frayne, R., & Lotufo, R. (2019). Convolutional neural networks for skull-stripping in brain MR imaging using silver standard masks. Artificial Intelligence in Medicine, 98(August 2018), 48–58. [[ https://doi.org/10.1016/j.artmed.2019.06.008][(link)]]
